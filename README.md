# ðŸ¦¾ BrailleAI â€” Braille Conversion Tool

> AI-powered Braille â†” Text conversion system using CNN-based ML models with ONNX inference.  
> Built for accessibility. Designed for everyone.

![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.110+-green?style=for-the-badge&logo=fastapi)
![React](https://img.shields.io/badge/React-18+-61DAFB?style=for-the-badge&logo=react)
![TypeScript](https://img.shields.io/badge/TypeScript-5+-3178C6?style=for-the-badge&logo=typescript)
![MySQL](https://img.shields.io/badge/MySQL-8.0+-orange?style=for-the-badge&logo=mysql)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=for-the-badge&logo=pytorch)
![ONNX](https://img.shields.io/badge/ONNX-Runtime-005CED?style=for-the-badge&logo=onnx)

---

## ðŸ“Œ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Getting Started](#-getting-started)
- [Environment Variables](#-environment-variables)
- [API Documentation](#-api-documentation)
- [ML Pipeline](#-ml-pipeline)
- [Contributing](#-contributing)

---

## ðŸ§  Overview

BrailleAI is a full-stack web application that converts:
- ðŸ“ **Text â†’ Braille**
- ðŸ–¼ï¸ **Image â†’ Braille** (via CNN-based OCR)
- ðŸ“„ **PDF â†’ Braille**
- ðŸ”¤ **Braille â†’ Text**

The system uses a **real trained CNN model exported to ONNX** for fast inference,  
wrapped in a **FastAPI async backend** and a **React + TypeScript frontend**.

---

## âœ¨ Features

### Frontend
- ðŸ” JWT Authentication (Register / Login / Logout / Refresh)
- â™¿ Full Accessibility Panel (High Contrast, Font Size, Screen Reader, Reduced Motion, Keyboard Navigation)
- ðŸ“Š Dashboard with conversion stats and history
- ðŸ–¼ï¸ Image upload with drag & drop for Braille image recognition
- ðŸ“‹ Clipboard copy support
- ðŸ” Conversion history with search
- ðŸ‘¤ User profile management
- ðŸ“± Fully responsive UI
- ðŸŒ™ Dark mode by default

### Backend
- âš¡ Async FastAPI with SQLAlchemy 2.0
- ðŸ”’ JWT Access + Refresh tokens with bcrypt hashing
- ðŸ—„ï¸ MySQL database with full async ORM models
- ðŸ¤– ONNX Runtime ML inference engine
- ðŸ§  CNN-based Braille cell detector + classifier
- ðŸ“ File upload & storage management
- ðŸ“‹ Full audit logging system
- ðŸ”„ Background job processing
- ðŸ“Š Analytics service
- ðŸ“§ Email service
- ðŸ³ Docker support

---

## ðŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| Frontend | React 18, TypeScript, Vite, TailwindCSS |
| State Management | Zustand + persist middleware |
| Routing | React Router v6 |
| Animations | Framer Motion |
| HTTP Client | Axios |
| Backend | FastAPI, Python 3.11+ |
| ORM | SQLAlchemy 2.0 async |
| Database | MySQL 8.0 |
| Migrations | Alembic |
| Auth | JWT (python-jose) + bcrypt |
| ML Training | PyTorch 2.0+ |
| ML Inference | ONNX Runtime |
| ML Preprocessing | OpenCV, Pillow |
| Containerization | Docker + Docker Compose |

---

## ðŸ“ Project Structure

```
braille-conversion-tool/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ alembic/                        # Alembic migration config
â”‚   â”‚   â””â”€â”€ versions/
â”‚   â”‚       â””â”€â”€ 001_initial_tables.py
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚   â”‚       â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ auth.py         # Register, Login, Refresh, Logout
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ braille.py      # Text â†” Braille conversion
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ documents.py    # Document management
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ export.py       # Export results
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ health.py       # Health check
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ history.py      # Conversion history
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ inference.py    # ML inference
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ jobs.py         # Job status
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ ocr.py          # OCR extraction
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ recognition.py  # Braille recognition
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ upload.py       # File upload
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ users.py        # User management
â”‚   â”‚   â”‚       â””â”€â”€ router.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py               # Settings & env vars
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py         # Shared FastAPI deps
â”‚   â”‚   â”‚   â”œâ”€â”€ exceptions.py           # Custom exceptions
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py              # Logging setup
â”‚   â”‚   â”‚   â””â”€â”€ security.py             # JWT & password utils
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ migrations/             # DB migration scripts
â”‚   â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ user.py             # User model
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ document.py         # Document model
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ conversion_job.py   # Job model
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ inference_result.py # Inference result model
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ audit_log.py        # Audit log model
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â””â”€â”€ session.py
â”‚   â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ artifacts/              # Trained model files (.pt, .onnx)
â”‚   â”‚   â”‚   â”œâ”€â”€ data/                   # Training data
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluation/             # Evaluation & metrics
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate_pipeline.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics_report.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tesseract_baseline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ export/                 # ONNX export & quantization
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ export_to_onnx.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ quantize_dynamic.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ benchmark_latency.py
â”‚   â”‚   â”‚   â”œâ”€â”€ inference/              # Inference pipeline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ braille_classifier.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ braille_detector.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cell_classifier_cnn.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dot_detector_cnn.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ postprocess.py
â”‚   â”‚   â”‚   â”œâ”€â”€ nlp/                    # NLP post-processing
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ nlp_postprocess.py
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing/          # Image preprocessing
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ binarize.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ denoise.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ perspective.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ resize.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ unwarp.py
â”‚   â”‚   â”‚   â””â”€â”€ training/               # Model training scripts
â”‚   â”‚   â”‚       â”œâ”€â”€ train_classifier.py
â”‚   â”‚   â”‚       â”œâ”€â”€ train_detector.py
â”‚   â”‚   â”‚       â”œâ”€â”€ train_cell_classifier.py
â”‚   â”‚   â”‚       â”œâ”€â”€ train_dot_detector.py
â”‚   â”‚   â”‚       â”œâ”€â”€ dataset.py
â”‚   â”‚   â”‚       â”œâ”€â”€ augmentations.py
â”‚   â”‚   â”‚       â”œâ”€â”€ losses.py
â”‚   â”‚   â”‚       â””â”€â”€ callbacks.py
â”‚   â”‚   â”œâ”€â”€ schemas/                    # Pydantic schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ braille.py
â”‚   â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â”‚   â”œâ”€â”€ export.py
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â”‚   â”œâ”€â”€ job.py
â”‚   â”‚   â”‚   â”œâ”€â”€ recognition.py
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py
â”‚   â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ services/                   # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ braille_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ document_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ email_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ export_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ inference_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ job_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ recognition_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ storage_service.py
â”‚   â”‚   â”‚   â””â”€â”€ user_service.py
â”‚   â”‚   â”œâ”€â”€ tests/                      # Unit & integration tests
â”‚   â”‚   â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_braille.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_ml_models.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_ocr.py
â”‚   â”‚   â”‚   â””â”€â”€ test_recognition_pipeline.py
â”‚   â”‚   â”œâ”€â”€ utils/                      # Utility helpers
â”‚   â”‚   â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ image_utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ text_utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ validators.py
â”‚   â”‚   â”‚   â””â”€â”€ response_utils.py
â”‚   â”‚   â””â”€â”€ main.py                     # FastAPI app entry point
â”‚   â”œâ”€â”€ uploads/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ exports/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ AccessibilityPanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Footer.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Loading.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Sidebar.tsx
â”‚   â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â”‚   â”œâ”€â”€ AccessibilityContext.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AccessibilityContextValue.ts
â”‚   â”‚   â”‚   â””â”€â”€ useAccessibility.ts
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useAuth.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useClipboard.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useConversion.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useDebounce.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useHistory.ts
â”‚   â”‚   â”‚   â””â”€â”€ useLocalStorage.ts
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ BrailleToText.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ History.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageToBraille.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ NotFound.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Profile.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Register.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TextToBraille.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ .env
â”œâ”€â”€ database/
â”œâ”€â”€ docs/
â”œâ”€â”€ mobile/
â”œâ”€â”€ storage/
â””â”€â”€ README.md
```

---

## ðŸš€ Getting Started

### Prerequisites

- Python 3.11+
- Node.js 18+
- MySQL 8.0+
- Git
- Docker (optional)

---

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/braille-conversion-tool.git
cd braille-conversion-tool
```

---

### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
venv\Scripts\activate          # Windows
# source venv/bin/activate     # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Copy env file and fill in values
copy .env.example .env

# Start the server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

---

### 3. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Copy env file
copy .env.example .env

# Start dev server
npm run dev
```

---

### 4. Database Setup

```sql
CREATE DATABASE braille_db
  DEFAULT CHARACTER SET utf8mb4
  COLLATE utf8mb4_unicode_ci;

CREATE USER 'braille_user'@'localhost' IDENTIFIED BY 'yourpassword';
GRANT ALL PRIVILEGES ON braille_db.* TO 'braille_user'@'localhost';
FLUSH PRIVILEGES;
```

> âœ… Tables are created **automatically** on first server start via SQLAlchemy.

---

### 5. Docker Setup (Alternative)

```bash
cd backend
docker-compose up --build
```

---

## ðŸ”‘ Environment Variables

### Backend `.env`

```env
# Database
DATABASE_URL=mysql+aiomysql://braille_user:yourpassword@localhost:3306/braille_db

# Security
SECRET_KEY=your-super-secret-key-minimum-32-chars
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# App
ENVIRONMENT=development
ALLOWED_ORIGINS=["http://localhost:5173"]
ALLOWED_HOSTS=["localhost", "127.0.0.1"]

# ML
MODEL_ARTIFACTS_DIR=./app/ml/artifacts

# Storage
UPLOAD_DIR=./uploads
MAX_FILE_SIZE_MB=10
```

### Frontend `.env`

```env
VITE_API_URL=http://localhost:8000/api/v1
```

---

## ðŸ“– API Documentation

Once backend is running, visit:

| URL | Description |
|-----|-------------|
| `http://localhost:8000/api/docs` | Swagger UI (interactive) |
| `http://localhost:8000/api/redoc` | ReDoc |
| `http://localhost:8000/health` | Root health check |

### Key Endpoints

```
AUTH
POST   /api/v1/auth/register         Register new user
POST   /api/v1/auth/login            Login â†’ returns JWT tokens
POST   /api/v1/auth/refresh          Refresh access token
POST   /api/v1/auth/logout           Logout
POST   /api/v1/auth/change-password  Change password

USERS
GET    /api/v1/users/me              Get current user profile
PUT    /api/v1/users/me              Update profile
GET    /api/v1/users/                List all users (admin only)
DELETE /api/v1/users/{id}            Delete user (admin only)

CONVERSION
POST   /api/v1/braille/convert       Text â†’ Braille / Braille â†’ Text
POST   /api/v1/ocr/extract           Extract text from image
POST   /api/v1/inference/run         Run full ML inference pipeline
POST   /api/v1/recognition/recognize Braille cell recognition

FILES
POST   /api/v1/upload                Upload image/PDF file
GET    /api/v1/documents             List user documents
GET    /api/v1/documents/{id}        Get document details
DELETE /api/v1/documents/{id}        Delete document

JOBS & HISTORY
GET    /api/v1/jobs                  List conversion jobs
GET    /api/v1/jobs/{id}             Get job status
GET    /api/v1/history               Conversion history

EXPORT
POST   /api/v1/export                Export result as PDF/TXT/BRF

HEALTH
GET    /api/v1/health                API health + model status
GET    /health                       Root health check
```

---

## ðŸ¤– ML Pipeline

The system uses a **two-stage CNN pipeline**:

```
Input Image
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Preprocessing      â”‚  â†’ Denoise, Binarize, Perspective Correction, Unwarp
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dot Detector CNN   â”‚  â†’ Detects individual Braille dots
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cell Classifier CNN â”‚  â†’ Classifies Braille cells (64 patterns)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NLP Postprocess    â”‚  â†’ Translates cells â†’ text, grammar correction
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Output Text
```

### Trained Model Artifacts

| File | Description |
|------|-------------|
| `detector.onnx` | Braille dot detector (ONNX) |
| `classifier.onnx` | Braille cell classifier (ONNX) |
| `detector_best.pt` | Best detector checkpoint |
| `classifier_best.pt` | Best classifier checkpoint |
| `evaluation_report.json` | Model evaluation metrics |
| `latency_benchmark.json` | Inference speed benchmark |

### Train the Models

```bash
cd backend

# Generate synthetic training data
python app/ml/training/generate_synthetic_data.py

# Train dot detector
python app/ml/training/train_dot_detector.py

# Train cell classifier
python app/ml/training/train_cell_classifier.py

# Export to ONNX
python app/ml/export/export_to_onnx.py

# Quantize for faster inference
python app/ml/export/quantize_dynamic.py

# Evaluate pipeline
python app/ml/evaluation/evaluate_pipeline.py

# Or run everything at once
python quick_train.py
```

---

## ðŸ§ª Running Tests

```bash
cd backend

# Run all tests
pytest app/tests/ -v

# Run specific test
pytest app/tests/test_auth.py -v
pytest app/tests/test_ml_models.py -v
pytest app/tests/test_recognition_pipeline.py -v
```

---

## ðŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. Commit your changes
   ```bash
   git commit -m "feat: add amazing feature"
   ```
4. Push to the branch
   ```bash
   git push origin feature/amazing-feature
   ```
5. Open a Pull Request

---

## ðŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](backend/LICENSE) file for details.

---

## ðŸ‘¥ Team

Built with â¤ï¸ at **Hacknight** by the BrailleAI team.

> Making the world more accessible â€” one braille cell at a time. â™¿
